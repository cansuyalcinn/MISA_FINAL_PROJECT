{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from metadata import ImageDataset, patient\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current directory is: /home/ricardino/Documents/MAIA/tercer_semestre/MISA/final_project/MISA_FINAL_PROJECT/notebooks\n"
     ]
    }
   ],
   "source": [
    "notebooks_path = Path.cwd()\n",
    "repo_path = notebooks_path.parent\n",
    "print(f'The current directory is: {notebooks_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the propagated labels, as well as a metric for the similarity between the registered images.<br>\n",
    "We can now build several versions of the atlas.\n",
    "We start with the most common, the **probabilistic atlas**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic atlas\n",
    "\n",
    "- All atlases (labels) are summed up and divided by the number of images. This is basically weighted voting with the same weight for all images (1/n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each patient in the validation, we will accumulate the labels, summing them.\n",
    "im_data_val = ImageDataset(set_name='Validation')\n",
    "im_data_train = ImageDataset(set_name='Training')\n",
    "#dataframe to store probabilistic atlas\n",
    "df_maxMean = None\n",
    "for id_val in im_data_val.IDs:\n",
    "    #instantiate patient\n",
    "    pat_val = patient(id_val, im_data_val)\n",
    "    #accumulated label array\n",
    "    accumulated_label = np.zeros((4,) + pat_val.im(format='np').shape)\n",
    "    for id_train in im_data_train.IDs:\n",
    "        moved_label_path = repo_path / 'data'/'voxelmorph'/f'moved_labels_{id_train}_to_{id_val}.nii.gz'\n",
    "        moved_label = utils.getArrayfromPath(moved_label_path)\n",
    "        #accumulate per tissue\n",
    "        for tissue in range(1,4):\n",
    "            accumulated_label[tissue] += (moved_label==tissue)\n",
    "    #divide by the number of labels\n",
    "    accumulated_label /= im_data_train.len\n",
    "\n",
    "    #Now we can take the argmax of the accumulated label to get the final mean atlas label\n",
    "    maxMean_label = np.argmax(accumulated_label, axis=0)\n",
    "    #get gorund truth\n",
    "    groundT = pat_val.labels(format='np')\n",
    "    #compute the dice score\n",
    "    dice = [utils.dice_score(groundT==tissue, maxMean_label==tissue) for tissue in range(1,4)]\n",
    "    #save the dice score in a dataframe. The first column is the id_val, then CSF, GM, WM\n",
    "    df_dice = pd.DataFrame([[id_val] + dice], columns=['id_val', 'CSF', 'GM', 'WM'])\n",
    "    #concatenate in df_maxM\n",
    "    df_maxMean = pd.concat([df_maxMean, df_dice], axis=0)\n",
    "#save as csv\n",
    "df_maxMean.to_csv(repo_path / 'data'/'results'/f'maxMean_dice.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted atlas\n",
    "\n",
    "- Similar to the previous one, but the weights are not the same for all images. The weights are the similarity metric between the registered images and the target (validation) image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define image datasets\n",
    "im_data_val = ImageDataset(set_name='Validation')\n",
    "im_data_train = ImageDataset(set_name='Training')\n",
    "#dataframe to store probabilistic atlas\n",
    "df_weightedAtlas = None\n",
    "\n",
    "for id_val in im_data_val.IDs:\n",
    "    #instantiate patient\n",
    "    pat_val = patient(id_val, im_data_val)\n",
    "    #array to store the weighted atlas\n",
    "    weighted_atlas = np.zeros((4,) + pat_val.im(format='np').shape)\n",
    "\n",
    "    #Compute the sum of similarity metrics for this validation patient\n",
    "    df_mostSimilar = pd.read_csv(repo_path / 'data'/'results'/'most_similar'/ f'most_similar_{id_val}.csv')\n",
    "    #get metric values and sum them up\n",
    "    sigma = df_mostSimilar['metric'].abs().sum()\n",
    "\n",
    "    for id_train in im_data_train.IDs:\n",
    "        moved_label_path = repo_path / 'data'/'voxelmorph'/f'moved_labels_{id_train}_to_{id_val}.nii.gz'\n",
    "        moved_label = utils.getArrayfromPath(moved_label_path)\n",
    "        #get similarity metric value\n",
    "        simMetric = df_mostSimilar[df_mostSimilar['id_train']==int(id_train)]['metric'].abs().values[0]\n",
    "        #accumulate per tissue\n",
    "        for tissue in range(1,4):\n",
    "            weighted_atlas[tissue] += (moved_label==tissue)*(simMetric/sigma) #wieghting by the similarity metric\n",
    "\n",
    "\n",
    "    #get argmax of the weighted atlas\n",
    "    weighted_label = np.argmax(weighted_atlas, axis=0)\n",
    "    #get gorund truth\n",
    "    groundT = pat_val.labels(format='np')\n",
    "    #compute the dice score\n",
    "    dice = [utils.dice_score(groundT==tissue, weighted_label==tissue) for tissue in range(1,4)]\n",
    "    #save the dice score in a dataframe. The first column is the id_val, then CSF, GM, WM\n",
    "    df_dice = pd.DataFrame([[id_val] + dice], columns=['id_val', 'CSF', 'GM', 'WM'])\n",
    "    #concatenate in df_maxM\n",
    "    df_weightedAtlas = pd.concat([df_weightedAtlas, df_dice], axis=0)\n",
    "    #save as csv\n",
    "    df_weightedAtlas.to_csv(repo_path / 'data'/'results'/f'weighted_labels_dice.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misa_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cff243af6c3d0a2893d2e87262cea0e9d750ffc752eaeb95474b08792ecfb50d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
