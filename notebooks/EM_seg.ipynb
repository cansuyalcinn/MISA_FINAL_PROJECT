{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import multivariate_normal\n",
    "import utils\n",
    "from metadata import ImageDataset, patient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current directory is: /home/ricardino/Documents/MAIA/tercer_semestre/MISA/final_project/MISA_FINAL_PROJECT/notebooks\n"
     ]
    }
   ],
   "source": [
    "notebooks_path = Path.cwd()\n",
    "repo_path = notebooks_path.parent\n",
    "print(f'The current directory is: {notebooks_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pixels(im_list:list, mask:np.ndarray):\n",
    "    \"\"\"extract pixels from a list of images based on a mask\n",
    "\n",
    "    Args:\n",
    "        im_list (list): list of images\n",
    "        mask (np.ndarray): mask to extract the pixels\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: extracted pixels flattened\n",
    "    \"\"\"\n",
    "    ims_flat = [x[mask!=0] for x in im_list]\n",
    "    extracted = np.stack(ims_flat).T\n",
    "    extracted = extracted.reshape(extracted.shape[0], -1)\n",
    "    \n",
    "    return extracted\n",
    "\n",
    "def reindexing(alphas:np.ndarray, means:list, covs:list):\n",
    "    \"\"\"Reindexing function designed to avoid the probelm of the order of tissue ordering after kmeans initialization\n",
    "\n",
    "    Args:\n",
    "        alphas (np.ndarray): alpha values\n",
    "        means (list): list of means\n",
    "        covs (list): list of covariances\n",
    "\n",
    "    Returns:\n",
    "        same as input: same three inputs but reordered\n",
    "    \"\"\"\n",
    "\n",
    "    means_np = np.vstack(means) #turn means into numpy array\n",
    "    covs_np = np.vstack(covs) #turn covs into numpy array\n",
    "    idx = np.argsort(means_np[:,0]) #get indexing for sorting\n",
    "    means_np = means_np[idx] #reorder\n",
    "    covs_np = covs_np[idx] #reorder\n",
    "    alphas = alphas[idx] #reorder\n",
    "    means = [means_np[i] for i in range(3)] #restore\n",
    "    covs = [covs_np[i] for i in range(3)] #restore\n",
    "    \n",
    "    return alphas, means, covs\n",
    "\n",
    "def init_kmeans(extracted:np.ndarray, n_components=3):\n",
    "    \"\"\"performs kmenas to extracted pixles\n",
    "\n",
    "    Args:\n",
    "        extracted (array): extracted pixels\n",
    "        n_components (in): number of components\n",
    "\n",
    "    Returns:\n",
    "        array, list, list: alphas, means and covariances\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_components) #3 tissue types\n",
    "    labels = kmeans.fit_predict(extracted) #predict labels\n",
    "    centers = kmeans.cluster_centers_ #predict centers\n",
    "    alphas = np.ones(n_components)/n_components #init alphas\n",
    "    \n",
    "    for i, cluster in enumerate(np.unique(labels)):\n",
    "        alphas[i] = np.sum(labels==cluster)/labels.shape[0] #update alphas\n",
    "    \n",
    "    means = []\n",
    "    covs = []\n",
    "    \n",
    "    for cluster in range(n_components):\n",
    "        means.append(centers[cluster])\n",
    "        covs.append(np.cov(extracted[labels==cluster].T))\n",
    "        \n",
    "    return reindexing(alphas, means, covs)\n",
    "\n",
    "def E_step(extracted, n_components, alphas, means, covs):\n",
    "    \"\"\"expectation step of em algorithm\n",
    "\n",
    "    Args:\n",
    "        extracted (array): pixels to be used for the intensity model\n",
    "        n_components (int): number of clusters\n",
    "        alphas (array): alphas of the EM model\n",
    "        means (array): means fo the clusters\n",
    "        covs (array): covariance matrix of the clusters\n",
    "\n",
    "    Returns:\n",
    "        arrays: pk and wk according to the EM algorithm\n",
    "    \"\"\"\n",
    "    pk = np.zeros((extracted.shape[0], n_components))\n",
    "    for cluster in range(n_components):\n",
    "        pk[:,cluster] = alphas[cluster] * multivariate_normal.pdf(extracted, mean=means[cluster], cov=covs[cluster]) #weigted pk calculation\n",
    "    wk = np.zeros((extracted.shape[0], n_components))\n",
    "    for cluster in range(n_components):\n",
    "        wk[:,cluster] = pk[:,cluster]/np.sum(pk, axis=1) #wk calculation\n",
    "    \n",
    "    return pk, wk\n",
    "\n",
    "def M_step(wk, n_components, extracted, means, covs):\n",
    "    \"\"\"maximisation step of em algorithm\n",
    "\n",
    "    Args:\n",
    "        wk (array): wk value as descibed in the EM algorithm\n",
    "        n_components (int): number of components in clustering\n",
    "        extracted (array): extracted pixels\n",
    "        means (list): list of means\n",
    "        covs (list): list of covariances\n",
    "\n",
    "    Returns:\n",
    "        array, list and list: parameters of EM algorithm\n",
    "    \"\"\"\n",
    "    nk = np.sum(wk, axis=0) #nk calculation\n",
    "    alphas = nk/wk.shape[0] #alphas calculation\n",
    "    for cluster in range(n_components):\n",
    "        means[cluster] = np.sum(wk[:,cluster][:,np.newaxis] * extracted, axis=0)/nk[cluster]\n",
    "    for cluster in range(n_components):\n",
    "        covs[cluster] = (wk[:,cluster][:,np.newaxis]*(extracted-means[cluster])).T @ (extracted-means[cluster])/nk[cluster]\n",
    "    return alphas, means, covs\n",
    "\n",
    "def log_likehood(pk):\n",
    "    \"\"\"returns log likehood of the model\n",
    "\n",
    "    Args:\n",
    "        pk (array): pk as descibed in the EM algorithm\n",
    "\n",
    "    Returns:\n",
    "        float: value of the log likehood\n",
    "    \"\"\"\n",
    "    return np.log(pk.sum(axis=1)).sum()\n",
    "\n",
    "def ll_diff(pk, prev_log, new_log):\n",
    "    \"\"\"difference between log likehoods\n",
    "\n",
    "    Args:\n",
    "        pk (array): pk as descibed in the EM algorithm\n",
    "        prev_log (float): previous log likehood\n",
    "        new_log (float): new log likehood\n",
    "\n",
    "    Returns:\n",
    "        float: absolute difference between log likehoods\n",
    "    \"\"\"\n",
    "    prev_log = new_log\n",
    "    new_log = log_likehood(pk)\n",
    "    return abs(new_log - prev_log), prev_log, new_log\n",
    "\n",
    "def get_seg(im_list, wk, mask):\n",
    "    \"\"\"given wk returns final segmentation\n",
    "\n",
    "    Args:\n",
    "        wk (array): wk array of EM algorithm\n",
    "    \"\"\"\n",
    "    labels = np.argmax(wk, axis=1) + 1 #get labels\n",
    "    seg_mask = np.zeros(im_list[0].shape) #create empy mask\n",
    "    seg_mask[mask!=0] = labels #assign pixels to empy maskEl c'odigo\n",
    "    \n",
    "    return seg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_segmentation(im_list:list, id:str, seg_name:str, n_tissue=3):\n",
    "    \"\"\"initial segemntation coming from previously obtained segmentations\n",
    "\n",
    "    Args:\n",
    "        im_list (list): images of the patient\n",
    "        id (str): id of the patient (same as in the dataset)\n",
    "        seg_name (str): name of the segmentation used\n",
    "        n_tissue (int, optional): number of tissues. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, list, list: alphas, means and covariances\n",
    "    \"\"\"\n",
    "    #get segmentation\n",
    "    seg = utils.getArrayfromPath(str(repo_path / 'data'/'segmentations'/f'{seg_name}_{id}_seg.nii.gz'))\n",
    "    #get image\n",
    "    im = im_list[0]\n",
    "    #init means and covariances\n",
    "    means = []\n",
    "    covs = []\n",
    "    for i in range(1,n_tissue+1):\n",
    "        extracted = np.extract(seg==i, im) #extract pixels of each tissue\n",
    "        means.append(extracted.mean()) #append mean\n",
    "        covs.append(np.cov(extracted.T)) #append covariance\n",
    "        \n",
    "    #initialize alphas\n",
    "    alphas = np.ones(n_tissue)/n_tissue #evenly distributed\n",
    "    n = np.extract(seg!=0, im).shape[0] #number of pixels\n",
    "    for i in range(1,n_tissue+1):\n",
    "        alphas[i-1] = np.sum(seg==i)/n #update alphas\n",
    "        \n",
    "    return alphas, means, covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(im_list:list, mask:np.ndarray, init_method:str):\n",
    "    \"\"\"EM algorithm\n",
    "\n",
    "    Args:\n",
    "        im_list (list): list of images to be used (of the same patient)\n",
    "        mask (np.ndarray): attention mask where pixels will be extracted\n",
    "        init_method (str): initialisation method\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, list: segmentation and list with log likehoods differences\n",
    "    \"\"\"\n",
    "\n",
    "    #first we extract the pixels under the mask\n",
    "    extracted = extract_pixels(im_list, mask)\n",
    "\n",
    "    #select initalisation method\n",
    "    if init_method == 'kmeans':\n",
    "        alphas, means, covs = init_kmeans(extracted, n_components=3)\n",
    "\n",
    "    #Stopping criteria\n",
    "    prev_log = 0\n",
    "    new_log = 2\n",
    "    error = 10e-6\n",
    "    iter_num = 500    \n",
    "\n",
    "    #store diff in list\n",
    "    diff_list = []\n",
    "    #start loop\n",
    "    for i in range(iter_num):\n",
    "        #EM step\n",
    "        pk, wk = E_step(extracted, n_components=3, alphas=alphas, means=means, covs=covs)\n",
    "        #M step\n",
    "        alphas, means, covs = M_step(wk, n_components=3, extracted=extracted, means=means, covs=covs)\n",
    "        #ll calculation\n",
    "        diff, prev_log, new_log = ll_diff(pk, prev_log, new_log)\n",
    "        #store diff in list\n",
    "        diff_list.append(diff)\n",
    "        if diff < error: #check if error is small enough\n",
    "            break\n",
    "\n",
    "    #final segmentation\n",
    "    seg_mask = get_seg(im_list, wk, mask)\n",
    "    \n",
    "    return seg_mask, diff_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to apply the EM algorithm on the validaiton images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:45<00:00, 57.11s/it]\n"
     ]
    }
   ],
   "source": [
    "im_data_val = ImageDataset(set_name='Validation')\n",
    "#EM initialisation method\n",
    "init_method = 'kmeans'\n",
    "#empy df to store results\n",
    "df_EM = None\n",
    "\n",
    "#LOOP starts here\n",
    "for id_val in tqdm(im_data_val.IDs):\n",
    "    #define pat\n",
    "    pat_val = patient(id_val, im_data_val)\n",
    "    #define list of images\n",
    "    im_list = [pat_val.im(format='np', preprocess=False)]\n",
    "    #define mask using all pixels in the image that are not zero\n",
    "    mask = im_list[0]>0\n",
    "\n",
    "    #first we extract the pixels under the mask\n",
    "    extracted = extract_pixels(im_list, mask)\n",
    "\n",
    "    #select initalisation method\n",
    "    if init_method == 'kmeans':\n",
    "        alphas, means, covs = init_kmeans(extracted)\n",
    "    else:\n",
    "        alphas, means, covs = init_segmentation(im_list, id_val, seg_name=init_method)\n",
    "\n",
    "    #Stopping criteria\n",
    "    prev_log = 0\n",
    "    new_log = 2\n",
    "    error = 10e-6\n",
    "    iter_num = 500    \n",
    "\n",
    "    #store diff in list\n",
    "    diff_list = []\n",
    "    #start loop\n",
    "    for i in range(iter_num):\n",
    "        #EM step\n",
    "        pk, wk = E_step(extracted, n_components=3, alphas=alphas, means=means, covs=covs)\n",
    "        #M step\n",
    "        alphas, means, covs = M_step(wk, n_components=3, extracted=extracted, means=means, covs=covs)\n",
    "        #ll calculation\n",
    "        diff, prev_log, new_log = ll_diff(pk, prev_log, new_log)\n",
    "        #store diff in list\n",
    "        diff_list.append(diff)\n",
    "        if diff < error: #check if error is small enough\n",
    "            break\n",
    "\n",
    "    #final segmentation\n",
    "    seg_mask = get_seg(im_list, wk, mask)\n",
    "\n",
    "    #compute metrics\n",
    "    df_metrics = utils.compute_metrics(seg_mask, pat_val, id_val)\n",
    "    #concatenate in df_maxM\n",
    "    df_EM = pd.concat([df_EM, df_metrics], axis=0)\n",
    "#save the dataframe\n",
    "df_EM.to_csv(repo_path / 'data'/'results'/f'EM_{init_method}_metrics.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM into and after\n",
    "- Now we can use the probabilistic atlas into and after the EM algorithm\n",
    "The probabilistic atlas could be:\n",
    "    - Top atlases probabilities\n",
    "    - Bayesian atlases probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c1f01218bbaf8a302f18173488403fcc9591627716b9a07a59bd925307e4c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
